---
epic: 1
story: 2
title: Deputy Catalog Ingestion
status: Done
priority: High
clickup:
  task_id: ""
  epic_task_id: ""
  list: "Backlog"
  url: ""
  last_sync: ""
---

# Story 1.2: Deputy Catalog Ingestion

As the system,  
I want to fetch and store the basic data of all 513 deputies,  
so that the search function has immediate data.

## ğŸ¯ Acceptance Criteria
- [x] AC1: Service correctly calls the `/deputados` endpoint of the Chamber API.
- [x] AC2: Data for all 513 active deputies is fetched.
- [x] AC3: Data is stored in the `deputies` table (id, name, party, state, photo_url).
- [x] AC4: Duplicate handling implemented (upsert logic).

## ğŸ› ï¸ Dev Notes

### Architecture Context
- **External API**: `https://dadosabertos.camara.leg.br/api/v2/deputados`. [Source: architecture/external-apis.md]
- **Data Model**: `Deputy` interface defined with id, nome, siglaPartido, siglaUf. [Source: architecture/data-models.md]
- **Database**: PostgreSQL `deputies` table. [Source: architecture/database-schema.md]

### Technical Constraints
- **Rate Limit**: API has undocumented limits; implement sequential fetching if necessary.
- **Sync Source**: Mark data source as 'api'.

## ğŸ¤– CodeRabbit Integration
> **CodeRabbit Integration**: Disabled

## ğŸ“ Tasks / Subtasks
- [x] Task 1: Create PostgreSQL table `deputies` in Supabase as defined in `docs/architecture/database-schema.md`.
- [x] Task 2: Create a sync function (or script) in `src/functions/sync-api/` to fetch data from the Chamber API.
- [x] Task 3: Map API response to the `deputies` table schema.
- [x] Task 4: Implement the sync logic using Supabase client to UPSERT data.
